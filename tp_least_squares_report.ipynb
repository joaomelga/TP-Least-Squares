{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data_center_helper as dch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A = dch.A\n",
    "b = dch.b\n",
    "\n",
    "A_test = dch.A_test\n",
    "b_test = dch.b_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3.1 Show that if Aw = b, they y(t) = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3.2 Solve this least squares problem using the funtion numpy.linalg.lstsq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00927821,  0.08309371, -0.03672704, ...,  0.01980595,\n",
       "       -0.03057174, -0.01188614])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "w_lstsq = result[0]\n",
    "w_lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-34.42662697,  -2.0426121 ,  -6.64183385, ...,   0.26999621,\n",
       "        -5.3032061 ,   3.66876618])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_stats = np.linalg.solve(A.T @ A, A.T @ b)\n",
    "w_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3.3 Evaluate the quality of the solution found on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  780.8984793523297\n"
     ]
    }
   ],
   "source": [
    "b_hat_lstsq = np.dot(A_test, w_lstsq)\n",
    "mse_lstsq = np.mean((b_test - b_hat_lstsq)**2)\n",
    "\n",
    "\"\"\" plt.scatter(b_test, b_hat)\n",
    "plt.xlabel('b_test')\n",
    "plt.ylabel('b_hat')\n",
    "plt.title('Relationship between b_test and b_hat')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "print('MSE: ', mse_lstsq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  16606709.6181741\n"
     ]
    }
   ],
   "source": [
    "b_hat_stats = np.dot(A_test, w_stats)\n",
    "mse_stats = np.mean((b_test - b_hat_stats)**2)\n",
    "\n",
    "print('MSE: ', mse_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3.4 In order to improve the generalization power of the model, we consider a $L_2$ regularization:\n",
    "\n",
    "$$\n",
    "\\min_w \\frac{1}{2} \\| A w - b \\|^2 + \\frac{\\lambda}{2} \\| w \\|^2\n",
    "$$\n",
    "\n",
    "where $\\lambda = 100$. Solve this problem and compare the test mean square error with the unregularized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  301.05482809422307\n"
     ]
    }
   ],
   "source": [
    "lmbda = 100\n",
    "w_l2 = np.linalg.solve(np.dot(A.T, A) + lmbda * np.eye(A.shape[1]), np.dot(A.T, b))\n",
    "\n",
    "b_hat_l2 = np.dot(A_test, w_l2)\n",
    "\n",
    "mse_l2 = np.mean((b_test - b_hat_l2)**2)\n",
    "print('MSE: ', mse_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3.5 Calculate the gradient of f1 : w -> $ \\frac{1}{2} \\| A w - b \\|^2 + \\frac{\\lambda}{2} \\| w \\|^2$\n",
    "\n",
    "Let's calculate the gradient in two steps:\n",
    "\n",
    "1. Differentiate $|| A w - b ||^2$ with respect to $w$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w} \\| A w - b \\|^2 = \\frac{\\partial}{\\partial w} ((A w - b)^T (A w - b))\n",
    "$$\n",
    "\n",
    "Using the chain rule and the fact that $(A w - b)^T (A w - b) = || A w - b ||^2 $:\n",
    "\n",
    "$$\n",
    "= 2A^T(Aw - b)\n",
    "$$\n",
    "\n",
    "2. Differentiate $ \\| w \\|^2 $ with respect to $ w $:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w} \\| w \\|^2 = \\frac{\\partial}{\\partial w} (w^T w)\n",
    "$$\n",
    "\n",
    "Using the chain rule and the fact that $ w^T w = \\| w \\|^2 $:\n",
    "\n",
    "$$\n",
    "= 2w\n",
    "$$\n",
    "\n",
    "Now, combine the results with the scaling factors:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w} f_1(w) = \\frac{\\partial}{\\partial w} \\left(\\frac{1}{2} \\| A w - b \\|^2 + \\frac{\\lambda}{2} \\| w \\|^2\\right) = A^T(Aw - b) + \\lambda w\n",
    "$$\n",
    "\n",
    "So, the gradient of $ f_1 $ with respect to $ w $ is $ A^T(Aw - b) + \\lambda w $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of f1: [ 1.09956488e-12  4.52970994e-14 -1.77496906e-13 ... -7.67830244e-13\n",
      "  2.83018053e-12 -3.24518190e-12]\n"
     ]
    }
   ],
   "source": [
    "gradient = np.dot(A.T, np.dot(A, w_l2) - b) + lmbda * w_l2\n",
    "\n",
    "print(\"Grad of f1:\", gradient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
